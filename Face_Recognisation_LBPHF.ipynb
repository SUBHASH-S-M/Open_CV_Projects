{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import smtplib\n",
    "from gtts import gTTS \n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils #resize reshaping cropping fedd from camera\n",
    "\n",
    "import time\n",
    "import os #to handle directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=r\"C:\\Users\\91759\\Desktop\\project-set-2\\pantech\\haarcascade_frontalface_default.xml\"\n",
    "\n",
    "haarcscade=cv2.CascadeClassifier(algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"classifierdataset\"\n",
    "name=\"subh\"\n",
    "path=os.path.join(dataset,name)\n",
    "if not os.path.isdir(path):  #checking a directory exist or not\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_captured\n"
     ]
    }
   ],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "(width,height)=(130,100)\n",
    "count=1\n",
    "while count<31:\n",
    "    \n",
    "    _,img=cam.read()\n",
    "    gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=haarcscade.detectMultiScale(gray_image,1.3,4) #detdct co-ordinates\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        onlyFace=gray_image[y:y+h,x:x+w]\n",
    "        resize_img=cv2.resize(onlyFace,(width,height))\n",
    "        cv2.imwrite(\"%s/%s.jpg\"%(path,count),resize_img)\n",
    "        count+=1\n",
    "    cv2.imshow(\"Face_detection\",img)\n",
    "    key=cv2.waitKey(10)\n",
    "    \n",
    "    if key==27:\n",
    "         break\n",
    "print(\"face_captured\")\n",
    "cam.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[102 105 102 ...  23  12   5]\n",
      "  [102  98 100 ...  25  19   6]\n",
      "  [101  96  89 ...  28  26   8]\n",
      "  ...\n",
      "  [ 33  30  27 ...  24  22  21]\n",
      "  [ 37  33  29 ...  30  25  25]\n",
      "  [ 40  35  31 ...  33  28  28]]\n",
      "\n",
      " [[107 105 107 ...  10   9   9]\n",
      "  [104 102 100 ...   6   3   4]\n",
      "  [107 106 103 ...   6   7   7]\n",
      "  ...\n",
      "  [ 62  75  78 ...  90  55  34]\n",
      "  [ 67  68  66 ... 127 126 112]\n",
      "  [ 55  51  46 ... 130 130 131]]\n",
      "\n",
      " [[ 97  94  69 ...   1   2   1]\n",
      "  [100  85  60 ...   0   5   5]\n",
      "  [ 92  59  34 ...   6   5   5]\n",
      "  ...\n",
      "  [ 26  26  27 ...  22  15  11]\n",
      "  [ 24  24  25 ...  22  14  11]\n",
      "  [ 22  22  23 ...  22  12   9]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 52  51  50 ...  50  50  50]\n",
      "  [ 46  47  48 ...  49  49  49]\n",
      "  [ 39  39  39 ...  49  50  50]\n",
      "  ...\n",
      "  [ 26  25  23 ...  27  28  29]\n",
      "  [ 17  17  15 ...  29  31  32]\n",
      "  [ 12  12  11 ...  29  32  33]]\n",
      "\n",
      " [[ 53  54  54 ...  46  49  50]\n",
      "  [ 55  55  54 ...  47  49  49]\n",
      "  [ 49  51  52 ...  48  49  49]\n",
      "  ...\n",
      "  [ 26  27  28 ...  22  24  25]\n",
      "  [ 15  16  18 ...  23  24  25]\n",
      "  [ 11  12  13 ...  25  27  28]]\n",
      "\n",
      " [[ 59  60  59 ...  50  50  50]\n",
      "  [ 55  56  55 ...  51  47  47]\n",
      "  [ 49  50  51 ...  52  51  50]\n",
      "  ...\n",
      "  [ 10  12  13 ...  27  27  28]\n",
      "  [  6   9  10 ...  26  25  26]\n",
      "  [  4   7   8 ...  25  26  27]]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#subh,name-labels\n",
    "#imasges name 1.jpg 2.jpg is names\n",
    "#id(0) 1st flder name\n",
    "(images,labels,names,id)=([],[],{},0)\n",
    "#subdirs is named as classiferdatsets\n",
    "#dirs is folder named as subhash etc\n",
    "#files is named as 1,2,3,4,5.jpg\n",
    "for (subdirs,dirs,files) in os.walk(dataset):\n",
    "    for subdirs in dirs:\n",
    "        names[id]=subdirs\n",
    "        subjectpath=os.path.join(dataset,subdirs)\n",
    "        for filename in os.listdir(subjectpath):\n",
    "            paths=subjectpath+'/'+filename\n",
    "            label=id\n",
    "            images.append(cv2.imread(paths,0))\n",
    "            labels.append(int(label))\n",
    "        id+=1\n",
    "(width,height)=(130,100)\n",
    "(images,labels)=[numpy.array(lis) for lis in [images,labels] ]\n",
    "print(images,labels)            \n",
    "\n",
    "#30 images array plus label 0 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "#model=cv2.face.FisherFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training completed\n"
     ]
    }
   ],
   "source": [
    "model.train(images,labels)\n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "subh\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n",
      "Name\n"
     ]
    }
   ],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "(width,height)=(130,100)\n",
    "count=1\n",
    "while count<31:\n",
    "    \n",
    "    _,img=cam.read()\n",
    "    gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=haarcscade.detectMultiScale(gray_image,1.3,4) #detdct co-ordinates\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        onlyFace=gray_image[y:y+h,x:x+w]\n",
    "        resize_img=cv2.resize(onlyFace,(width,height))\n",
    "        prediction=model.predict(resize_img)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        if prediction[1]<800:\n",
    "            cv2.putText(img,\"%s - %.0f\"%(names[prediction[0]],prediction[1]),\n",
    "                       (x-20,y-10),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0))\n",
    "            print(names[prediction[0]])\n",
    "            count=0\n",
    "        else:\n",
    "            count+=1\n",
    "            cv2.putText(img,\"Unknown\",\n",
    "                       (x-20,y-10),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0))\n",
    "            if(count>100):\n",
    "                print(\"Unknown Person\")\n",
    "                cv2.imwrite(\"Input.jpg\",img)\n",
    "                count=0\n",
    "    cv2.imshow(\"OpenCV\",img)\n",
    "    key=cv2.waitKey(10)\n",
    "    if key==27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
